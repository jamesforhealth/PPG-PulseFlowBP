digraph {
	graph [size="52.35,52.35"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2382022422240 [label="
 (32, 2)" fillcolor=darkolivegreen1]
	2382000346864 [label=AddmmBackward0]
	2382000245824 -> 2382000346864
	2382022417840 [label="fc.bias
 (2)" fillcolor=lightblue]
	2382022417840 -> 2382000245824
	2382000245824 [label=AccumulateGrad]
	2382002769488 -> 2382000346864
	2382002769488 [label=CatBackward0]
	2382005499360 -> 2382002769488
	2382005499360 [label=MeanBackward1]
	2382005599536 -> 2382005499360
	2382005599536 [label=ConvolutionBackward0]
	2382005598912 -> 2382005599536
	2382005598912 [label=AddBackward0]
	2382005600016 -> 2382005598912
	2382005600016 [label=MulBackward0]
	2382005600160 -> 2382005600016
	2382005600160 [label=SliceBackward0]
	2382005600208 -> 2382005600160
	2382005600208 [label=ReluBackward0]
	2382022574288 -> 2382005600208
	2382022574288 [label=CudnnBatchNormBackward0]
	2382004909344 -> 2382022574288
	2382004909344 [label=ConvolutionBackward0]
	2382022574528 -> 2382004909344
	2382022574528 [label=AddBackward0]
	2382022574720 -> 2382022574528
	2382022574720 [label=MulBackward0]
	2382022574864 -> 2382022574720
	2382022574864 [label=ConstantPadNdBackward0]
	2382022575008 -> 2382022574864
	2382022575008 [label=ReluBackward0]
	2382022575104 -> 2382022575008
	2382022575104 [label=CudnnBatchNormBackward0]
	2382022575152 -> 2382022575104
	2382022575152 [label=ConvolutionBackward0]
	2382022575440 -> 2382022575152
	2382022575440 [label=ReluBackward0]
	2382022575632 -> 2382022575440
	2382022575632 [label=CudnnBatchNormBackward0]
	2382022575680 -> 2382022575632
	2382022575680 [label=ConvolutionBackward0]
	2382022575968 -> 2382022575680
	2382022575968 [label=ReluBackward0]
	2382022576160 -> 2382022575968
	2382022576160 [label=CudnnBatchNormBackward0]
	2382022576208 -> 2382022576160
	2382022576208 [label=ConvolutionBackward0]
	2382022576496 -> 2382022576208
	2382022576496 [label=SqueezeBackward1]
	2382022576688 -> 2382022576496
	2382022576688 [label=MaxPool2DWithIndicesBackward0]
	2382022576736 -> 2382022576688
	2382022576736 [label=UnsqueezeBackward0]
	2382022574672 -> 2382022576736
	2382022574672 [label=ReluBackward0]
	2382022576976 -> 2382022574672
	2382022576976 [label=CudnnBatchNormBackward0]
	2382022577120 -> 2382022576976
	2382022577120 [label=ConvolutionBackward0]
	2382022577408 -> 2382022577120
	2382022577408 [label=ReluBackward0]
	2382022577600 -> 2382022577408
	2382022577600 [label=CudnnBatchNormBackward0]
	2382022577648 -> 2382022577600
	2382022577648 [label=ConvolutionBackward0]
	2382022577936 -> 2382022577648
	2382022577936 [label=SqueezeBackward1]
	2382022578128 -> 2382022577936
	2382022578128 [label=MaxPool2DWithIndicesBackward0]
	2382022578176 -> 2382022578128
	2382022578176 [label=UnsqueezeBackward0]
	2382005599968 -> 2382022578176
	2382005599968 [label=ReluBackward0]
	2382022578416 -> 2382005599968
	2382022578416 [label=CudnnBatchNormBackward0]
	2382022578560 -> 2382022578416
	2382022578560 [label=ConvolutionBackward0]
	2382022578848 -> 2382022578560
	2382022578848 [label=ReluBackward0]
	2382022579040 -> 2382022578848
	2382022579040 [label=CudnnBatchNormBackward0]
	2382022579088 -> 2382022579040
	2382022579088 [label=ConvolutionBackward0]
	2382022579376 -> 2382022579088
	2382005796320 [label="encoder1.0.weight
 (32, 5, 3)" fillcolor=lightblue]
	2382005796320 -> 2382022579376
	2382022579376 [label=AccumulateGrad]
	2382022579328 -> 2382022579088
	2382005796400 [label="encoder1.0.bias
 (32)" fillcolor=lightblue]
	2382005796400 -> 2382022579328
	2382022579328 [label=AccumulateGrad]
	2382022578944 -> 2382022579040
	2382005796240 [label="encoder1.1.weight
 (32)" fillcolor=lightblue]
	2382005796240 -> 2382022578944
	2382022578944 [label=AccumulateGrad]
	2382022579184 -> 2382022579040
	2382005796480 [label="encoder1.1.bias
 (32)" fillcolor=lightblue]
	2382005796480 -> 2382022579184
	2382022579184 [label=AccumulateGrad]
	2382022578800 -> 2382022578560
	2382022410320 [label="encoder1.3.weight
 (32, 32, 3)" fillcolor=lightblue]
	2382022410320 -> 2382022578800
	2382022578800 [label=AccumulateGrad]
	2382022578752 -> 2382022578560
	2382022410400 [label="encoder1.3.bias
 (32)" fillcolor=lightblue]
	2382022410400 -> 2382022578752
	2382022578752 [label=AccumulateGrad]
	2382022578512 -> 2382022578416
	2382022410480 [label="encoder1.4.weight
 (32)" fillcolor=lightblue]
	2382022410480 -> 2382022578512
	2382022578512 [label=AccumulateGrad]
	2382022578656 -> 2382022578416
	2382022410560 [label="encoder1.4.bias
 (32)" fillcolor=lightblue]
	2382022410560 -> 2382022578656
	2382022578656 [label=AccumulateGrad]
	2382022577888 -> 2382022577648
	2382022410960 [label="encoder2.0.weight
 (64, 32, 3)" fillcolor=lightblue]
	2382022410960 -> 2382022577888
	2382022577888 [label=AccumulateGrad]
	2382022577840 -> 2382022577648
	2382022411040 [label="encoder2.0.bias
 (64)" fillcolor=lightblue]
	2382022411040 -> 2382022577840
	2382022577840 [label=AccumulateGrad]
	2382022577504 -> 2382022577600
	2382022411120 [label="encoder2.1.weight
 (64)" fillcolor=lightblue]
	2382022411120 -> 2382022577504
	2382022577504 [label=AccumulateGrad]
	2382022577744 -> 2382022577600
	2382022411200 [label="encoder2.1.bias
 (64)" fillcolor=lightblue]
	2382022411200 -> 2382022577744
	2382022577744 [label=AccumulateGrad]
	2382022577360 -> 2382022577120
	2382022411600 [label="encoder2.3.weight
 (64, 64, 3)" fillcolor=lightblue]
	2382022411600 -> 2382022577360
	2382022577360 [label=AccumulateGrad]
	2382022577312 -> 2382022577120
	2382022411680 [label="encoder2.3.bias
 (64)" fillcolor=lightblue]
	2382022411680 -> 2382022577312
	2382022577312 [label=AccumulateGrad]
	2382022577072 -> 2382022576976
	2382022411760 [label="encoder2.4.weight
 (64)" fillcolor=lightblue]
	2382022411760 -> 2382022577072
	2382022577072 [label=AccumulateGrad]
	2382022577216 -> 2382022576976
	2382022411840 [label="encoder2.4.bias
 (64)" fillcolor=lightblue]
	2382022411840 -> 2382022577216
	2382022577216 [label=AccumulateGrad]
	2382022576448 -> 2382022576208
	2382022412240 [label="encoder3.0.weight
 (128, 64, 3)" fillcolor=lightblue]
	2382022412240 -> 2382022576448
	2382022576448 [label=AccumulateGrad]
	2382022576400 -> 2382022576208
	2382022412320 [label="encoder3.0.bias
 (128)" fillcolor=lightblue]
	2382022412320 -> 2382022576400
	2382022576400 [label=AccumulateGrad]
	2382022576064 -> 2382022576160
	2382022412400 [label="encoder3.1.weight
 (128)" fillcolor=lightblue]
	2382022412400 -> 2382022576064
	2382022576064 [label=AccumulateGrad]
	2382022576304 -> 2382022576160
	2382022412480 [label="encoder3.1.bias
 (128)" fillcolor=lightblue]
	2382022412480 -> 2382022576304
	2382022576304 [label=AccumulateGrad]
	2382022575920 -> 2382022575680
	2382022412880 [label="encoder3.3.weight
 (128, 128, 3)" fillcolor=lightblue]
	2382022412880 -> 2382022575920
	2382022575920 [label=AccumulateGrad]
	2382022575872 -> 2382022575680
	2382022412960 [label="encoder3.3.bias
 (128)" fillcolor=lightblue]
	2382022412960 -> 2382022575872
	2382022575872 [label=AccumulateGrad]
	2382022575536 -> 2382022575632
	2382022413040 [label="encoder3.4.weight
 (128)" fillcolor=lightblue]
	2382022413040 -> 2382022575536
	2382022575536 [label=AccumulateGrad]
	2382022575776 -> 2382022575632
	2382022413120 [label="encoder3.4.bias
 (128)" fillcolor=lightblue]
	2382022413120 -> 2382022575776
	2382022575776 [label=AccumulateGrad]
	2382022575392 -> 2382022575152
	2382022413520 [label="decoder1.0.weight
 (128, 64, 2)" fillcolor=lightblue]
	2382022413520 -> 2382022575392
	2382022575392 [label=AccumulateGrad]
	2382022575344 -> 2382022575152
	2382022413600 [label="decoder1.0.bias
 (64)" fillcolor=lightblue]
	2382022413600 -> 2382022575344
	2382022575344 [label=AccumulateGrad]
	2382022574912 -> 2382022575104
	2382022413680 [label="decoder1.1.weight
 (64)" fillcolor=lightblue]
	2382022413680 -> 2382022574912
	2382022574912 [label=AccumulateGrad]
	2382022575248 -> 2382022575104
	2382022413760 [label="decoder1.1.bias
 (64)" fillcolor=lightblue]
	2382022413760 -> 2382022575248
	2382022575248 [label=AccumulateGrad]
	2382022574816 -> 2382022574720
	2382022574816 [label=SigmoidBackward0]
	2382022575296 -> 2382022574816
	2382022575296 [label=CudnnBatchNormBackward0]
	2382022575584 -> 2382022575296
	2382022575584 [label=ConvolutionBackward0]
	2382022576016 -> 2382022575584
	2382022576016 [label=ReluBackward0]
	2382022576880 -> 2382022576016
	2382022576880 [label=CudnnBatchNormBackward0]
	2382022577264 -> 2382022576880
	2382022577264 [label=ConvolutionBackward0]
	2382022578032 -> 2382022577264
	2382022578032 [label=CatBackward0]
	2382022574864 -> 2382022578032
	2382022574672 -> 2382022578032
	2382022577456 -> 2382022577264
	2382022414800 [label="attention1.0.weight
 (32, 128, 1)" fillcolor=lightblue]
	2382022414800 -> 2382022577456
	2382022577456 [label=AccumulateGrad]
	2382022577552 -> 2382022577264
	2382022414880 [label="attention1.0.bias
 (32)" fillcolor=lightblue]
	2382022414880 -> 2382022577552
	2382022577552 [label=AccumulateGrad]
	2382022576832 -> 2382022576880
	2382022414960 [label="attention1.1.weight
 (32)" fillcolor=lightblue]
	2382022414960 -> 2382022576832
	2382022576832 [label=AccumulateGrad]
	2382022576640 -> 2382022576880
	2382022415040 [label="attention1.1.bias
 (32)" fillcolor=lightblue]
	2382022415040 -> 2382022576640
	2382022576640 [label=AccumulateGrad]
	2382022576112 -> 2382022575584
	2382022415440 [label="attention1.3.weight
 (1, 32, 1)" fillcolor=lightblue]
	2382022415440 -> 2382022576112
	2382022576112 [label=AccumulateGrad]
	2382022576352 -> 2382022575584
	2382022415520 [label="attention1.3.bias
 (1)" fillcolor=lightblue]
	2382022415520 -> 2382022576352
	2382022576352 [label=AccumulateGrad]
	2382022575824 -> 2382022575296
	2382022415600 [label="attention1.4.weight
 (1)" fillcolor=lightblue]
	2382022415600 -> 2382022575824
	2382022575824 [label=AccumulateGrad]
	2382022574960 -> 2382022575296
	2382022415680 [label="attention1.4.bias
 (1)" fillcolor=lightblue]
	2382022415680 -> 2382022574960
	2382022574960 [label=AccumulateGrad]
	2382022574672 -> 2382022574528
	2382022574480 -> 2382004909344
	2382022414160 [label="decoder2.0.weight
 (64, 32, 2)" fillcolor=lightblue]
	2382022414160 -> 2382022574480
	2382022574480 [label=AccumulateGrad]
	2382022574432 -> 2382004909344
	2382022414240 [label="decoder2.0.bias
 (32)" fillcolor=lightblue]
	2382022414240 -> 2382022574432
	2382022574432 [label=AccumulateGrad]
	2382022574336 -> 2382022574288
	2382022414320 [label="decoder2.1.weight
 (32)" fillcolor=lightblue]
	2382022414320 -> 2382022574336
	2382022574336 [label=AccumulateGrad]
	2382022574144 -> 2382022574288
	2382022414400 [label="decoder2.1.bias
 (32)" fillcolor=lightblue]
	2382022414400 -> 2382022574144
	2382022574144 [label=AccumulateGrad]
	2382005600112 -> 2382005600016
	2382005600112 [label=SigmoidBackward0]
	2382022574384 -> 2382005600112
	2382022574384 [label=CudnnBatchNormBackward0]
	2382022574624 -> 2382022574384
	2382022574624 [label=ConvolutionBackward0]
	2382022577792 -> 2382022574624
	2382022577792 [label=ReluBackward0]
	2382022578272 -> 2382022577792
	2382022578272 [label=CudnnBatchNormBackward0]
	2382022577984 -> 2382022578272
	2382022577984 [label=ConvolutionBackward0]
	2382022578896 -> 2382022577984
	2382022578896 [label=CatBackward0]
	2382005600160 -> 2382022578896
	2382005599968 -> 2382022578896
	2382022578992 -> 2382022577984
	2382022416080 [label="attention2.0.weight
 (16, 64, 1)" fillcolor=lightblue]
	2382022416080 -> 2382022578992
	2382022578992 [label=AccumulateGrad]
	2382022579232 -> 2382022577984
	2382022416160 [label="attention2.0.bias
 (16)" fillcolor=lightblue]
	2382022416160 -> 2382022579232
	2382022579232 [label=AccumulateGrad]
	2382022578080 -> 2382022578272
	2382022416240 [label="attention2.1.weight
 (16)" fillcolor=lightblue]
	2382022416240 -> 2382022578080
	2382022578080 [label=AccumulateGrad]
	2382022576592 -> 2382022578272
	2382022416320 [label="attention2.1.bias
 (16)" fillcolor=lightblue]
	2382022416320 -> 2382022576592
	2382022576592 [label=AccumulateGrad]
	2382022575488 -> 2382022574624
	2382022416720 [label="attention2.3.weight
 (1, 16, 1)" fillcolor=lightblue]
	2382022416720 -> 2382022575488
	2382022575488 [label=AccumulateGrad]
	2382022575056 -> 2382022574624
	2382022416800 [label="attention2.3.bias
 (1)" fillcolor=lightblue]
	2382022416800 -> 2382022575056
	2382022575056 [label=AccumulateGrad]
	2382022574768 -> 2382022574384
	2382022416880 [label="attention2.4.weight
 (1)" fillcolor=lightblue]
	2382022416880 -> 2382022574768
	2382022574768 [label=AccumulateGrad]
	2382022574192 -> 2382022574384
	2382022416960 [label="attention2.4.bias
 (1)" fillcolor=lightblue]
	2382022416960 -> 2382022574192
	2382022574192 [label=AccumulateGrad]
	2382005599968 -> 2382005598912
	2382005598960 -> 2382005599536
	2382022417360 [label="final_conv.weight
 (1, 32, 1)" fillcolor=lightblue]
	2382022417360 -> 2382005598960
	2382005598960 [label=AccumulateGrad]
	2382005599152 -> 2382005599536
	2382022417440 [label="final_conv.bias
 (1)" fillcolor=lightblue]
	2382022417440 -> 2382005599152
	2382005599152 [label=AccumulateGrad]
	2382005599056 -> 2382002769488
	2382005599056 [label=AddmmBackward0]
	2382005599488 -> 2382005599056
	2382022417520 [label="personal_fc.bias
 (16)" fillcolor=lightblue]
	2382022417520 -> 2382005599488
	2382005599488 [label=AccumulateGrad]
	2382005599920 -> 2382005599056
	2382005599920 [label=TBackward0]
	2382005600064 -> 2382005599920
	2382022417280 [label="personal_fc.weight
 (16, 4)" fillcolor=lightblue]
	2382022417280 -> 2382005600064
	2382005600064 [label=AccumulateGrad]
	2382005599584 -> 2382002769488
	2382005599584 [label=AddmmBackward0]
	2382005599680 -> 2382005599584
	2382022417680 [label="vascular_fc.bias
 (16)" fillcolor=lightblue]
	2382022417680 -> 2382005599680
	2382005599680 [label=AccumulateGrad]
	2382022579280 -> 2382005599584
	2382022579280 [label=TBackward0]
	2382022574576 -> 2382022579280
	2382022417600 [label="vascular_fc.weight
 (16, 2)" fillcolor=lightblue]
	2382022417600 -> 2382022574576
	2382022574576 [label=AccumulateGrad]
	2382005599008 -> 2382000346864
	2382005599008 [label=TBackward0]
	2382005599872 -> 2382005599008
	2382022417760 [label="fc.weight
 (2, 33)" fillcolor=lightblue]
	2382022417760 -> 2382005599872
	2382005599872 [label=AccumulateGrad]
	2382000346864 -> 2382022422240
}
